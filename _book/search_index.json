[
["index.html", "The Complex Systems Approach to Behavioural Science A practical guide", " The Complex Systems Approach to Behavioural Science Fred Hasselman &amp; Maarten Wijnants 2017 - 2018 A practical guide Image from Grip on Complexity "],
["course-guide.html", "Course guide", " Course guide Complexity research transcends the boundaries between the classical scientific disciplines and is a hot topic in physics, mathematics, biology, economy as well as psychology and the life sciences and is collectively referred to as the Complexity Sciences. This course will discuss techniques that allow for the study of human behaviour from the perspective of the Complexity Sciences, specifically, the study of complex physical systems that are alive and display complex adaptive behaviour such as learning and development. Contrary to what the term “complex” might suggest, complexity research is often about finding simple models / explanations that are able to simulate a wide range of qualitatively different behavioural phenomena. “Complex” generally refers to the object of study: Complex systems are composed of many constituent parts that interact with one another across many different temporal and spatial scales to generate behaviour at the level of the system as a whole that can appear to be periodic, nonlinear, unstable or extremely persistent. The focus of many research designs and analyses is to quantify the degree of periodicity, nonlinearity, context sensitivity or resistance to perturbation by exploiting the fact that “everything is interacting” in complex systems. This requires a mathematical formalism and rules of scientific inference that are very different from the mathematics underlying traditional statistical analyses that assume “everything is NOT interacting” in order to be able to validly infer statistical regularities in a dataset and generalise them to a population. The complex systems approach to behavioural science often overlaps with the idiographical approach of the science of the individual, that is, the goal is not to generalise properties or regularities to universal or statistical laws that hold at the level of infinitely large populations, but to apply general principles and universal laws that govern the adaptive behaviour of all complex systems to study specific facts, about specific systems observed in specific contexts at a specific instant. The main focus of the course will be hands-on data-analysis and the main analytical tool we will use is R (if you are an expert: It is also possible to use Matlab for most of the assignments, let us know in advance). Practical sessions will follow after a lecture session in which a specific technique will be introduced. We will cover the following topics: Theoretical background of phase transitions (self-organised criticality) and synchronisation (coupling dynamics) in complex dynamical systems and networks. Simple models of linear and nonlinear dynamical behaviour (Linear &amp; logistic growth, Predator-Prey dynamics, Lorenz system, the chaos game); Analysis of long range dependence in time and trial series (Entropy, Relative roughness, Standardized Dispersion Analysis, Detrended Fluctuation Analysis). Quantification of temporal patterns in time and trial series including dyadic interactions (Phase Space Reconstruction, [Cross] Recurrence Quantification Analysis). Network analyses (Estimating symptom networks, calculating network based complexity measures) "],
["teaching-formats.html", "Teaching formats", " Teaching formats Each meeting starts with a lecture addressing the theoretical and methodological backgrounds of the practical applications that will be used in hands-on assignments during the practical sessions. Several meetings include a part where guest lecturers discuss the use of one or more techniques in their recent research. Preparation To prepare for each lecture students should read the assigned chapters in this book and contribute to the 7 discussion assignments. Participating in the discussion assignments is a required part of this course. At the end of the course we will check whether each student has posted at least one question or answer for each assignment. We will not judge the content of the posts, but in order to pass, we need at least 7 posts, one for each assignment. The answers will be discussed during the subsequent lecture. Using Cerego We have to introduce a lot of new terminology and to help students get acquainted with these terms, they can use Cerego. An invitation will be sent to all participants of the course. The list of term is also included as Appendix A. Test information Examination will be based on a final assignment and a check of participation in weekly discussions on blackboard (the content of contributions will not be evaluated). Specifically: To prepare for each lecture students read a contemporary research paper in which a complex systems approach is used to a phenomenon studied in behavioural science. Students are required to formulate questions about each paper, and to initiate a discussion with their fellow-students on Blackboard. Each week at least one post by each student is expected in the discussion forum. A final take-home assignment will be provided at the end of the course. Details will be discussed during the course. In general, the assignment will take about 2 days to complete, the time available to complete the assignment will be 1-2 weeks depending on the schedule. This course is for students of the Research Master Behavioural Science. Other Research Master students and PhD students interested in following the course ask for permission by emailing to rm@bsi.ru.nl until 3 weeks before the start of the course. If permission is granted, this will be emailed 2 weeks before the start of the course. Please confirm this mail! PhD students (RU and external) have to subscribe through http://www.ru.nl/socialewetenschappen/onderwijs/overig/aanschuifonderwijs This course is not available for Bachelor and Master students. "],
["learning-objectives.html", "Learning objectives", " Learning objectives Specific Students who followed this course will be able to: Critically evaluate whether their scientific inquiries can benefit from adopting theories, models, methods and analyses that were developed in the Complexity Sciences to study the structure and behaviour of complex adaptive systems. Understand the differences between using an independent-statistical-component-dominant causal ontology, versus an interdependent-dynamical-interaction-dominant approach to the scientific study of human behaviour. Understand and apply important terms to describe behavioural change and adaptation: Nonlinear dynamics (e.g. hysteresis), attractor state, order parameter, control parameter, state-space, phase-space, phase transition, self-organisation, emergence, synergies as coordinative structures. Simulate linear, nonlinear and coupled growth using simple mathematical models in Excel and R (or Matlab). Fit parameters of simple models of linear and nonlinear growth to real data in SPSS or R (or Matlab). Perform analyses on time and trial series of human performance and physiology that quantify the presence and nature of scaling relations (fractal geometry) in continuous or categorical data in R (or Matlab). Perform analyses on time and trial series of human performance and physiology that quantify the presence and nature of temporal patterns (recurrent trajectories in phase space) in continuous or categorical data data in R (or Matlab). Perform network analyses on datasets that may be considered static or dynamical representations of social networks, or symptom networks (psychopathology) in R. Understand the results from analyses in terms of early warning signals indicating a phase transition might be imminent. Understand the results from analyses in terms of synchronisation and coupling phenomena, e.g. “complexity matching” and “leading/following” behaviour. General At the end of this course, students have reached a level of understanding that will allow them to: Study relevant scientific literature using a complex systems approach to behavioural science. Getting help with using a complex systems approach in their own scientific inquiries, e.g. by being able to ask relevant questions to experts on a specific topic discussed during the course. Work through tutorials on more advanced topics that were not discussed during the course. Keep up with the continuous influx of new theoretical, methodological and empirical studies on applying the complex systems approach in the behavioural-, cognitive- and neurosciences. "],
["literature.html", "Literature", " Literature Main literature: Hasselman, F., &amp; Wijnants, M. (2018). A Complex Systems Approach to the Behavioural Sciences. A practical guide to basic theory, models, methods and analyses [this book] Rose, T. (2016). The end of average: How we succeed in a world that values sameness. Penguin UK. [also available in Dutch and many other languages] Selected chapters from these books will be made available to make a personal copy Friedenberg, J. (2009). Dynamical psychology: Complexity, self-organization and mind. ISCE Publishing. Kaplan, D., &amp; Glass, L. (2012). Understanding nonlinear dynamics. Springer Science &amp; Business Media. We als provide links to online materials on specific topics (Study Materials) that may provide additional explanation and information about key concepts. These materials are not obligatory, but highly recommended to study at least once. Notes about the online book and the assignments The texts in the chapters of this book are intended as a rough introductory guide to accompany the lectures, thet are still somewhat of a work in progress. We made everything as coherent as possible, sometimes though, you will notice a paragraph or chapter rather resembles a set of lecture notes instead of a self-contained text. Do not hesitate to let us know if you think anything is unclear or too far out of context for you to understand. An essential part of the course are the assignments that are available online The text inside these blocks provides important information about the course, the assignments, or the exam. The text inside these blocks provides examples, or, information about a topic you should pay close attentiont to and try to understand. The text inside these blocks provides a note, a comment, or observation. The content in these blocks are often questions about a topic, or, suggestions about connections between different topics discussed in the book and the assignments. You should decide for yourself if you need to dig deeper to answer the questions or if you want to discuss the content. One way to find an answer or start a discussion is to open a thread in the discussion forum on Blackboard labelled ThinkBox. The content in these blocks is provided as entertainment :) "],
["schedule.html", "Schedule", " Schedule The dates and locations can be found below. All lectures are on Thursday from 10.45 to 12.30. The practical sessions take place on Thursday from 13.45 to 15.30. "],
["we-use-r.html", "We use R!", " We use R! This text was transformed to HTML, PDF en ePUB using bookdown(Xie, 2016a) in RStudio, the graphical user interface of the statistical language R (R Core Team, 2016). bookdown makes use of the R version of markdown called Rmarkdown (Allaire et al., 2016), together with knitr (Xie, 2016c) and pandoc. We’ll use some web applications made in Shiny (Chang, Cheng, Allaire, Xie, &amp; McPherson, 2016) Other R packages used are: DT (Xie, 2016b), htmlTable (Gordon, 2016), plyr (Wickham, 2016a), dplyr (Wickham &amp; Francois, 2016),tidyr (Wickham, 2016b), png (Urbanek, 2013), rio (Chan &amp; Leeper, 2016). "],
["a-quick-guide-to-scientific-rigour.html", "Chapter 1 A Quick Guide to Scientific Rigour", " Chapter 1 A Quick Guide to Scientific Rigour “Meanwhile our eager-beaver researcher, undismayed by logic-of-science considerations and relying blissfully on the “exactitude” of modern statistical hypothesis-testing, has produced a long publication list and been promoted to a full professorship. In terms of his contribution to the enduring body of psychological knowledge, he has done hardly anything. His true position is that of a potent-but-sterile intellectual rake, who leaves in his merry path a long train of ravished maidens but no viable scientific offspring” —Paul Meehl (1967,p. 114) Before we can begin our introduction to the wonderful world of Complex Adaptive Systems and Complex Networks, we briefly discuss the philosophy of science and perspective on the goal of scientific inquiry that is used throughout this book. This will allow us to highlight some differences between the Complex Systems Approach (CSA) we propose for the scientific study of human nature and the classical and often implicit perspective used in most disciplines of the social and life sciences, we will call the Machine Metaphor Approach (MMA). Use of the scientific method scientific method is what seperates scientific from non-scientific claims about the structure of reality. It consists of all philosophical, theoretical and empirical tools, procedures and methods that can be used to systematically evaluate the veracity of such explanatory claims. The repeated application of the scientific method to study scientific questions promises to generate valid (accurate) inferences and reliable (precise) facts about a certain explanatory domain, but it is important to note it does not guarantee that any kind of absolute ‘truth’ will be discovered. The veracity of scientific inferences is always conditional on the quality of the body of scientific knowledge from which the inferences were deduced, induced or abducted. For example, when a crisis of confidence about the trustworthiness of the facts in the scientific record of some subdisciplines of psychological science was suggested (Pashler &amp; Wagenmakers, 2012), the immediate consequence was that the veracity of all claims by psychological science was called into question. Rigorous Open Science Less tangible, but not less important for the perceived veracity of scientific knowledge are concepts such as intellectual honesty and scientific integrity of the scientists laying explanatory claims on some domain in reality. Merely checking whether the scientific method has been applied does not fully grasp all the prerequisites for generating a solid body of knowledge. We will use the term rigorous open science to denote the ideal set of conditions that should be in place to allow us to distinguish scientific claims that are likely to be false, from claims that are likely to be true, given the perceived verisimilitude (thruth-likeness) of the knowledge accumulated in the scientific record. Figure 1.1: Rigorous Science according to Casadevall &amp; Fang (2016). When a claim is based on Scientific Rigour (Casadevall &amp; Fang, 2016), we mean it was posited based on the following set of principles: Experimental Redundancy - The claim has been examined by all methodological and analytical tools that are available and are appropriate given the context. Rigorous Science does not rely on one type of experimental design or one type of statistical analysis. Recognition of Error - Without failure there can be no progress, therefore we should carefully study failures and not just report success stories. Any sources of error should be carefully studied and reported to the scientific community. Sound Probability &amp; Statistics - Use of the most recent and appropriate statistical theories, models and analytical techniques. Statistical modelling techniques become more realistic over time and often the models that were taught in undergraduate statistics courses have long been replaced and should not be used any more. Efforts to Avoid Logical Traps - When generating theories and defining constructs and laws, make sure logical inconsistencies are avoided. When making inferences, avoid the common logical traps such as The Effect = Structure Fallacy in null hypothesis significance testing (NHST). Intellectual Honesty - Rigorous science is ethical, has integrity and thrives on critical reflection on scientific practice. The right mindset is “Prove yourself wrong!”, not “Prove yourself right!” We add to the list that science must be open and transparent. This may seem like an obvious statement to a fresh student of human behaviour, but concepts that make up an essential part of the scientific debate in 2017, such as open science, open data, reproducibility, Questionable Research Practices (QRPs), Hypothesizing After the Results are Known (HARKing) and preregistration, were practically unknown 5 years ago. Theoretical Tunnelvision “It is the theory that decides what we may observe” —Einstein (as quoted by Heisenberg) Many of the initiatives to improve science are focussed on methodology and statistics. This is understandable, because that’s where errors are easily made (and discovered) and allows for relatively simple interventions, such as more stingent control on appropriate use of statistics by journals. However, the goal of generating empirical facts is ultimately because we want to find out which scientific claim about the structure of reality best explains why those empirical facts were oserved. In other words: The quote attributed to Einstein refers to an important, and grossly underestimated phenomenon one might call the theoretical tunnelvision. It is best explained by an example that is commonly encountered in the literature in psychological science and goes something like this: A study tries to find independent causes (predictors) of a certain disease-entity, a pathological state or behavioural mode people can ‘get stuck in’. Typically, a statistical model fitted on a large, representative sample of individuals in which many different predictors were measured will yield associations between predictor and disease-entity that are significant but small (on average \\(r \\approx 0.3\\), or \\(\\approx 9\\%\\) explained variance). Often, if other known (non-clinical) covariates are included in a model, and even more so, if the multivariate nature of the phenomenon is taken seriously, for example by including repeated measurements and/or multiple dependent variables, these predictors will no longer explain any unique variance in the outcome measures. Here is an example from a ‘predictor’ study (Walker &amp; Druss, 2015) in a representative sample of 331 individuals who suffered from persistent MDD for at least 10 years: “Clinical variables in this analysis were not strongly associated with persistence of MDD over the course of 10 years. Comorbid generalized anxiety disorder, baseline depression severity, and taking a prescription for nerves, anxiety, or depression were significantly associated with persistent depression in the unadjusted logistic regression models, but the associations became non-significant when in the multivariate model. These findings are in contrast to the results from several other studies.” The study concludes by discussing three factors that play a statistically significant role in the persistance of MDD (text between brackets not in original): “having two or more chronic medical conditions [in 1995-1996] contributes to experiencing depression ten years later [2.89 more likely]. However, only having one chronic medical condition did not increase the odds of being classified as having MDD in 2004–2006.” “days of activity limitation in 1995–1996 were significantly associated with a greater risk of depression ten years later [2.19 more likely], independent of the number of chronic medical conditions a person had.” “Individuals who were in contact with family less than once a week [in 1995-1996] were more likely to have MDD in 2004–2006 [2.07 more likely]. Likewise, people who were married were less likely to have persistent depression compared to those who have never married [never married 2.42 more likely]” So what’s wrong with these inferences? The study shows some previous assumptions about the relevance of clinical predictors should be reconsidered, and it adds to scientific record some facts about risk factors that might have eluded scientists, clinicians and health professionals. Let’s look at the main conclusion of the study, in addition to a plea for more attention for people with two or more chronic medical conditions, Walker &amp; Druss (2015) end the article with: Future research should continue to examine the complex nature of the relationship between chronic medical disorders and comorbid psychiatric conditions. Addressing these conditions and strengthening social support systems could be important strategies for reduce the burden of depression. First, if clincal predictors play no role in explaining why some people remain depressed for such long periods of time, why isn’t the main conclusion of the study that we must re-appraise the scientific theories laying explanatory claim on the aetiology of MDD, from which the diagnostic tools, medical and psychological interventions to which these patients have been exposed were derived? Second, even though the authors acknowledge –and indeed show– that the propagation of a pathological state like MDD over many years is a very complex multivariate phenomenon, their suggestion for future research is still based on an implicit assumption about causation that is extremely simple. The idea is clearly that there is a chain of unique (efficient) causes, each contributing independently to the emergence, and persistence in time of the MDD state. The authors basically suggest some causes have tp be added to the causal chain. The metaphor used here is that of a machine of which the sum output of its constituent components is equal to the purpose or function of the machine as a whole. Should a component fail, then it can be repaired or replaced as long as it performs the same function as the defective part, thereby restoring the function of the machine as a whole. This is why the authors suggest that strengthening social support systems could be an intervention to recduce the burden of depression: The absence of a partner or visits by family members were predictors that explained some unique variance in the data on the persistence of MDD. Obviously, restoring this defective social support component should restore or at least fascilitate the escape from the MDD state. Meanwhile, they seem to forget that they convincingly argued that MDD is a very complex phenomenon that cannot be dissected into neat, independent component causes. Third, and very much related to the previous remark, the authors mention three important factors in the discussion and conclusion section, however, the results section contains another factor that was omitted, it is in fact the second most important predictor of the persistence of MDD: “Women had 2.48 the odds of remaining depressed compared to men” Why did they ignore this predictor in the discussion? This is speculation, but could it be that this factor is not mentioned because it would have to be considered a ‘deficient’ component and suggesting any kind of ‘treatment’ intended to ‘repair’ it is of course beyond the realm of sane things to suggest. Nevertheless, it does eem rather important to figure out why this is the case, starting by not considering gender a unique causal component in a chain of independent predictors might help. Instead, gender can be considered a complex aggregate, or, contextual variable that is associated to the dependent variable through a vast network of interdependent facts, events and states of affair. An obvious factor of importance is that effect studies of medical interventions are mainly conducted on white, male, 20-30 year old, right-handed, subjects with above average SES. Also, it is likely that on average, the stability of mood over longer periods of time is more variable in women than in men due to fluctations of hormone levels, it does not seem unreasonable to suggest this might pose extra challenges to women who seek to escape the strong pull of the MDD state. We could go on and very likely each sensible factor we come up with will have some part in the emergence of the association between gender and risk for persistent MDD. The analytical tools selected by the researchers (a generalized linear statistical model) restrict the kinds of associations we might observe in the data. In the the present case all associations will –after transformation– be linear compositions of independent components.1 One never reads this valid equally valid conclusion: “We conclude that the linear model is inadequate to describe the complexity of this phenomenon.” The reason is that the implicit assumptions about causality underlying scientific claims never enter the empirical cycle and therefore escape falsification by the repeated application of the scientific method even though those causality assumptions are also based on a scientific theory about the structure of reality that is in principle falsifiable. To be a bit more precise about the relationship between what theories assume to be constituent parts of reality and why, we discuss the differences between some important theoretical concepts. Naturally, if one would use mixed models we can account for dependencies in the data, but they will still be limited to linear associations.↩ "],
["formalism-ontology-and-epistemology.html", "1.1 Formalism, Ontology and Epistemology", " 1.1 Formalism, Ontology and Epistemology A difficulty of much psychological theorizing is vagueness in the terms employed. In this work, the above ideas have been studied in mathematical form throughout, the definitions and proofs being given corresponding precision. —W. R. Ashby in ‘The Physical Origin of Adaptation by Trial adn Error’ (Ashby (1945), p. 13) @[Meehl1990a,Meehl1997a] "],
["phenomena-theories-facts-and-laws.html", "1.2 Phenomena, theories, facts and laws", " 1.2 Phenomena, theories, facts and laws “All science is either physics or stamp collecting.” — Ernest Rutherford (Physics Nobel Laureate, 1872-1937) Properties of theories "],
["appraising-and-amending-theories.html", "1.3 Appraising and amending theories", " 1.3 Appraising and amending theories Strong Inference The Effect = Structure Fallacy refers to the logical error that occurs a predicted effect is observed (i.e. a statistically significant test result leads to a rejection of the null hypothesis), it is not valid to infer the existence of the assumed cause was evidenced. NHST is based on the falsification principle, which means the perceived veracity of a scientific claim will increase only if it has resist many rigorous attempts to prove it is wrong. If a scientific claim has a large track-record of resisting falsification Table 1.1: Strong Inference according to Platt (1964) Strong inference consists of applying the following steps to every problem in science, formally and explicitly and regularly: Devising alternative hypotheses Devising a crucial experiment (or several of them), with alternative possible outcomes, each of which will, as nearly as possible, exclude one or more of the hypotheses Carrying out the experiment so as to get a clean result 1’ Recycling the procedure, making subhypotheses or sequential hypotheses to refine the possibilities that remain … and so on. "],
["measurement-and-psychometrics.html", "1.4 Measurement and Psychometrics", " 1.4 Measurement and Psychometrics Table 1.2: Properties of Random Variables at Stevens’ Levels of Measurement (1962) Nominaal Ordinaal Interval Ratio Basale empirische methoden Determination of (in)equality Determination of ‘more’ or ‘less’ Determination of equality of intervals of differences Determination of equality of ratios Wiskundige operatoren \\(=\\ \\neq\\) \\(\\leq\\ \\geq\\) \\(+ \\ -\\) \\(\\times\\ \\div\\) Analyse Groeperen; Classificeren; Indiceren Sorteren; Vergelijken; Niveau bepalen Relatieve vergelijkingsbasis (meetlat): Relatief verschil of gelijkenis; relatief nulpunt Absolute vergelijkingsbasis (meetschaal): Verhoudingen van magnitudes / hoeveelheden; absoluut nulpunt Centrale tendentie Modus; Frequentie Mediaan; Percentielen Rekenkundig gemiddelde; Standaarddeviatie Geometrisch gemiddelde; Variatiecoëfficiën 1 Samenhang Nominale associatie (Contingentie coefficient, Phi, Kramer’s V, Lambda, \\(\\chi^2\\)) Directionele nominale associatie (Kendall’s tau a-c, Gamma, Somer’s D) Rangorde correlatie en Product-Moment correlatie (Spearman en Pearson correlatie) Kansverdelingen en informatie theorie (K-L divergence, Average Mutual Information) 1 https://nl.wikipedia.org/wiki/Variatiecoëfficiënt "],
["scientific-realism-in-the-post-truth-era.html", "1.5 Scientific Realism in the Post-Truth Era", " 1.5 Scientific Realism in the Post-Truth Era “At this point an enigma presents itself which in all ages has agitated inquiring minds. How can it be that mathematics, being after all a product of human thought which is independent of experience, is so admirably appropriate to the objects of reality? Is human reason, then, without experience, merely by taking thought, able to fathom the properties of real things? In my opinion the answer to this question is briefly this: As far as the laws of mathematics refer to reality, they are not certain; and as far as they are certain, they do not refer to reality.” —Albert Einstein (1921) Anti: Pessimistic meta-induction argument (French &amp; Ladyman, 2003): “There has been ontological discontinuity across theory-change. By induction we may conclude that it is most likely that the ontology of our currently accepted theories will also be radically revised sooner or later.” Pro: ‘No miracles’ argument (Ainsworth, 2010): “some scientific theories enjoy enormous empirical success; if these theories are not even approximately true, their success is miraculous; on the other hand, if these theories are approximately true, their success is not miraculous; we should thus infer that such theories are approximately true.” "],
["study-materials.html", "Study Materials", " Study Materials Clear explanation of the difference betweern phenomenon, hypothesis, theory en law Ontologie. Epistemologie "],
["introduction-to-complexity-science.html", "Chapter 2 Introduction to Complexity Science", " Chapter 2 Introduction to Complexity Science Psychological systems are biological systems which are physical systems that are alive. Therefore, any theory that lays explanatory claim to phenomena of the mind, ultimately must be a theory about how a physical system is able to accumulate non-random order into its internal structure that appears to codetermine its behaviour. Less formally stated, a science that studies the behaviour of physical systems that are alive, that appear to have a memory which makes their behaviour adaptive, future oriented, intelligent, should in principle be grounded in physical and biological principles and laws. That may be a bridge too far for now, but such theories should at least not contradict highly corroborated theories of physics that describe the behaviour of the constituent components of living systems. The best way to describe the differences between the Machine Metaphor Approach (MMA) and the Complex Systems Approach (CSA) to study human behaviour is to examine what theories generated using the each approach The Complex Systems Approach to Behavioural Science is mainly concerned with understanding be described as science "],
["psychological-sciences-information-infatuation.html", "2.1 Psychological Science’s Information Infatuation", " 2.1 Psychological Science’s Information Infatuation Er zijn nog veel meer problemen met de computer metafoor voor menselijke cognitie en gedrag, zoals de enorme ‘opslagcapaciteit’ die nodig zou zijn om alle mentale representaties van de externe wereld te bewaren, maar ook het probleem ‘nadenken’ voor ons altijd in termen van ‘betekenisvolle informatie’ verloopt. Onze interne monoloog lijkt op een stem die betekenisvolle taal spreekt, we denken niet na in abstracte symbolen. De wiskundige theorie van Claude Shannon, die het concept informatie voor het eerst definieerde, gaat helemaal niet over de inhoud van de informatie en ook niet over hoe informatie betekenis kan krijgen door het te decoderen. Het is een theorie over het communiceren van hoeveelheden informatie en heet daarom ook: A mathematical theory of communication. Als we de onderstaande passage lezen uit het artikel waarin Shannon zijn theorie poneerde, zou het weleens zo kunnen zijn dat de definitie van informatie en computatie (informatieverwerking) totaal verkeerd zijn begrepen door de sociale wetenschappers: “The fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point. Frequently the messages have meaning; that is they refer to or are correlated according to some system with certain physical or conceptual entities. These semantic aspects of communication are irrelevant to the engineering problem. The significant aspect is that the actual message is one selected from a set of possible messages. The system must be designed to operate for each possible selection, not just the one which will actually be chosen since this is unknown at the time of design.” —Shannon (1948, p.379) "],
["radical-embodied-cognition.html", "2.2 Radical Embodied Cognition", " 2.2 Radical Embodied Cognition De filosoof Andy Clark (1991) formuleerde het zogenaamde 007-principe dat deze uitgangspunten mooi samenvat: In general, evolved creatures will neither store nor process information in costly ways when they can use the structure of the environment and their operations upon it as a convenient stand-in for the information-processing operations concerned. That is, known only as much as you need to know to get the job done Het gaat er dus om te proberen gedrag te begrijpen als ‘belichaamd’ (embodied) en ‘gesitueerd’ in een omgeving of context (embedded) en niet als het resultaat van centrale informatieverwerkende processor (meestal het brein). In Figuur 2.1 is te zien wat precies wordt bedoeld met het onderscheid tussen interacties en componenten als verklaringen. Figure 2.1: Een overzicht van het verschil tussen interactie en component dominante causale ontologie. De oorzaken van dyslexie zijn dezelfde als de uit Figuur ?? Such behavior is often called ‘adaptive’ to indicate that the same external states could elicit different behavioral responses depending on the temporal order in which they occur (e.g. reward before vs. after an electric shock; cf. (???), (???)). One important requirement for dependence of system behavior on the temporal order of event occurrences, is that the physical composition of the system must permit specification of its internal structure by the particular facts pertaining to the events (see e.g. (???), (???), (???)). If the after-effects of an interaction of the system with its environment are reflected by systematic changes to the internal structure of a system (e.g., evidenced as correlations between internal and external states such as ‘neural correlates’), the system can be characterized as a memory system. Specification of the physical structure of a system through after-effects of interactions (‘experienced’ events), is the only conceivable way to permit the coordination of behavior in the present (the Now) by the past (cf. (???)). The Complex Systems Approach to Behavioural Science is mainly concerned with understanding be described as science The conception of particular facts as discrete internalized states dates back at least to 1904 when Richard Semon defined the engram' as the unique physiological trace left in the central nervous system by each stimulus and thing that an organism had experienced or learned ~\\citep*[see][]{Bruce2001a, McConnell1965a}. Related to the concept of the engram is theassociative chain theory’~ or `path theory’ of the central nervous system: “I refer to `path theory’, which states, roughly, that the functions of the central nervous system are controlled by chains of neurons laid down as a path so as to conduct the impulse to its appropriate end-organ: that the paths are strictly constant, thus accounting for the fact that the reflexes and reactions are largely constant: that learning consists of the opening up of new paths and that memory consists of the retraversing of some old path by another impulse.”&quot; — (???) Both the engram and path theory turned out to be elusive theoretical constructs. After a lifetime spent searching for the engram, Lashley announced his failure to detect it ~ and with respect to the emergence of order in sequences of behavior out of chains of associations: “I believe, that such interpretations of temporal organization are untenable and that there are, behind the overtly expressed sequences, a multiplicity of integrative processes which can only be inferred from the final results of their activity.”&quot; — (???) Gibson’s quoted vision of the brain as a self-tuning resonator was based on Lashley’s criticism of the brain as a storehouse (see Table~). The storehouse and path metaphors are apparently too compelling, especially in the behavioral-, cognitive-, and neurosciences (BCN science) the brain is commonly referred to as a storage medium ~ and overt behavior as the result of executing a program ~. The internal, or mental representation is a modern version of the engram and plays a crucial role in modern theorizing about intelligent behavior. Remarkably, despite its importance as a theoretical entity, a formal definition is missing. In terms of a physical system, internal representation refers to: \\textit{an identifiable physical state within a system that stands in for another (internal or external) state and that as such plays a causal role in (or is used by) the system generating its behavior}''~\\citep*[][p. 6]{Haselager2003a}. From a realist perspective, any theory about mental phenomena that makes use of internal representations and imprinted `paths' or `traces' to explain adaptive behavior, will have to explain how the system was specified to represent (aspects of) an interaction event. In BCN science, this is generally neglected and many accounts of the physical realization of adaptive behavior must be characterized as `feigned physicalism'. Ashby already noted in 1931, that the path theory~. The goal of this article is to introduce a number of physical principles and explanatory tools that allow the development of a formalism for complex adaptive behavior based a conception of computation that respects the physical medium of implementation~. A formalism for Radical Embodied Computation (REC++) should describe order generation inside brains nested in bodies that can explain phenomena of the mind departing from principles of Information Realism ~. REC++ can be described as an attempt to merge Radical Embodied Cognition ~ and Physical Intelligence~ with Natural Computation ~. Potential issues with this objective are he explicit rejection of the use of information-theoretic constructs by REC in which: ``’’ ~ and the requirement by PI of information to become more than a measure of uncertainty ~. These and related issues will be discussed throughout the text. First, I will follow Ashby’s lead and test the explanatory boundaries of Radical Neuronal Reductionism (RNR) that is commonly used as a causal ontology for adaptive behavior in BCN science ~. "],
["what-is-a-complex-dynamical-system.html", "2.3 What is a Complex Dynamical System?", " 2.3 What is a Complex Dynamical System? A system is an entity that can be described as a composition of components, according to one or more organizing principles. The organizing prniciples can take many different forms, but essentially they decide the three important features of systems that have to do with the relationship between parts and wholes: What are the relevant scales of observation of the system What are the relevant phenomena that may be observed at the different scales Can interactions with the internal and external environment occur, and if so, do interactions have any effects on the structure and/or behaviour of the system 2.3.1 Open vs. Closed A closed system cannot exchange any energy, matter or information with the external environment. 2.3.2 Simple vs. Complex 2.3.3 Ergodic vs. Non-ergodic (???,(???)) 2.3.4 Equilibrium vs. Far-from-equilibrium 2.3.5 Order vs. Disorder “order is essentially the arrival of redundancy in a system, a reduction of possibilities” — Von Förster (2003) The arrival of redundancy is an excellent description of what is meant by nonrandom behaviour. If the behaviour of a system is redundant, this means it is predictable to some extent and this just refers to the fact that behaviour covaries systematically (is correlated) with the behaviour of other parts of the system, or with changes in the external environment. The presence of redundancies indeed implies a reduction of possible states the system has available to generate its behaviour, the states a system can be in are in some way dependent on the temporal evolution of parts of the internal or external environment, they can no longer be occupied independently. This phenomenon id often described as a constraint on the degrees of freedom a system has available to generate its behaviour. The appearance of order always implies that states that were previously part of the behaviourial repertoire, are no longer accessible by the system. The opposite of order, disorder, or randomness, must then refer to the absolute absence of any redundancies, making reliable prediction of system behaviour impossible, or, equilly reliable to what may be expected by chance. The amount of disorder in a system can be quantified, a measure known as the Entropy of a system. 2.3.6 Order vs. Deterministic Chaos "],
["a-causal-ontology-of-interaction-dynamics.html", "2.4 A Causal Ontology of Interaction Dynamics", " 2.4 A Causal Ontology of Interaction Dynamics 2.4.1 Holism and Emergence “A physical theory is holistic if and only if it is impossible in principle, for a set of local agents each having access to a single subsystem only, to infer the global properties of a system as assigned in the theory (which can be inferred by global measurements), by using the resource basis available to the agents.” 2.4.2 "],
["state-space.html", "2.5 State Space", " 2.5 State Space "],
["phase-space.html", "2.6 Phase Space", " 2.6 Phase Space "],
["the-attractor-ladscape.html", "2.7 The Attractor Ladscape", " 2.7 The Attractor Ladscape Equilibrium State It occurs when a dynamic system has a configuration C with the properties that a. if started at C and released, it does not move from C, and b. if started at any configuration near C, the system changes in time towards C. "],
["introduction-to-the-mathematics-of-change.html", "Chapter 3 Introduction to the Mathematics of Change ", " Chapter 3 Introduction to the Mathematics of Change "],
["statistic-versus-dynamic-models.html", "3.1 Stat(ist)ic versus Dynamic Models", " 3.1 Stat(ist)ic versus Dynamic Models The simplest non-trivial iterative change process can be described by the following difference equation: \\[ Y_{t+1} = Y_{t=0} + a*Y_t \\] The equation describes the way in which the value of \\(Y\\) changes between two adjacent, discrete moments in time (hence the term difference equation, or recurrence relation). There are two parameters resembling an intercept and a slope: The starting value \\(Y_0\\) at \\(t=0\\), also called the starting value, or the initial conditions. A rule for incrementing time, here the change in \\(Y\\) takes place over a discrete time step of 1: \\(t+1\\). The values taken on by variable \\(Y\\) are considered to represent the states quantifiable observable leAlternative ways to describe the change of states : A dynamical rule describing the propagation of the states of a system observable measured by the values of variable Y through discrete time. A dynamic law describing the time-evolution of the states of a system observable measured by the variable Y. These descriptions all refer to the change processes that govern system observables (properties of dynamical systems that can be observed through measurement). 3.1.1 It’s a line! It’s a plane! The formula resembles the equation of a line. There is a constant value \\(Y_{0}\\) which is added to a proportion of the value of \\(Y\\) at time \\(t\\), given by parameter \\(a\\). This is equivalent to the slope of a line. However, in a \\((X,Y)\\) plane there are two ‘spatial’ (metric) dimensions representing the values two variables \\(X\\) and \\(Y\\) can take on (see figure). The best fitting straight line would be called a statistical model of the linear relationship between the observed values of \\(X\\) and \\(Y\\). It can be obtained by fitting a General Linear Model (GLM) to the data. If \\(X\\) were to represent repeated measurements the multivariate GLM for repeated measures would have to be fitted to the data. This can be very problematic, because statistical models rely on Ergodic theory: “… it is the study of the long term average behavior of systems evolving in time.” In other words: If you throw 1 die 100 times in a row, the average of the 100 numbers is the time-average of one of the observables of die-throwing systems. If this system is ergodic, then its time-average is expected to be similar to the average of the numbers that turn up if you throw 100 dice all at the same instance of time. The dice layed out on the table represent a spatial sample, a snapshot frozen in time, of the possible states the system can be in. Taking the average would be the spatial average this observable of die-throwing systems. This ergodic condiciotn is often implicitly assumed in Behavioural Science when studies claim to study change by taking different samples of individuals (snapshots of system states) and comparing if they are the same. need to assume independence of measurements within and between subjects. These assumptions can be translated to certain conditions that must hold for the model to be valid, known as Compound Symmetry and Sphericity: The compound symmetry assumption requires that the variances (pooled within-group) and covariances (across subjects) of the different repeated measures are homogeneous (identical). This is a sufficient condition for the univariate F test for repeated measures to be valid (i.e., for the reported F values to actually follow the F distribution). However, it is not a necessary condition. The sphericity assumption is a necessary and sufficient condition for the F test to be valid; it states that the within-subject “model” consists of independent (orthogonal) components. The nature of these assumptions, and the effects of violations are usually not well-described in ANOVA textbooks;2 As you can read in the quoted text above, these conditions must hold in order to be able to identify unique independent components as the sources of variation of \\(Y\\) over time within a subject. This is the a clear example of: If you choose to use GLM repeated measures to model change over time, you will only be able to infer independent components that are responsible for the time-evolution of \\(Y\\). As is hinted in the last sentence of the quote, the validity of such inferences is not a common topic of discussion statistics textbooks. 3.1.2 No! … It’s a time series! The important difference between a regular 2-dimensional Euclidean plane and the space in which we model change processes is that the \\(X\\)-axis represents the physical dimension time. In the case of the Linear Map we have a 1D space with one ‘spatial’ dimension \\(Y\\) and a time dimension \\(t\\). This is called time series if \\(Y\\) is sampled as a continuous process, or a trial series if the time between subsequent observations is not relevant, just the fact that there was a temporal order (for example, a series of response latencies to trials in a psychological experiment in the order in which they were presented to the subject). Time behaves different from a spatial dimension in that it is directional (time cannot be reversed), it cannot take on negative values, and, unless one is dealing with a truly random process, there will be a temporal correlation across one or more values of \\(Y\\) seperated by an amount of time. In the linear difference equation this occurs because each value one step in the future is calculated based on the current value. If the values of \\(Y\\) represent an observable of a dynamical system, the system can be said to have a history, or a memory. Ergodic systems do not have a history or a memory that extends across more than one time step. This is very convenient, because one can calculate the expected value of a system observable given infinite time, by making use of of the laws of probabilities of random events (or random fields). This means: The average of an observable of an Ergodic system measured across infinite time (its entire history, the time-average), will be the be the same value as the average of this observable measured at one instance in time, but in an infinite amount of systems of the same kind (the population, the spatial average) [^dice]. The simple linear difference equation will have a form of perfect memory across the smallest time scale (i.e., the increment of 1, \\(t+1\\)). This ‘memory’ just concerns a correlation of 1 between values at adjacent time points (a short range temporal correlation, SRC), because the change from \\(Y_t\\) to \\(Y_{t+1}\\) is exactly equal to \\(a * Y_t\\) at each iteration step. This is the meaning of deterministic, not that each value of \\(Y\\) is the same, but that the value of \\(Y\\) now can be perfectly explained form the value of \\(Y\\) one moment in the past. Summarising, the most profound difference is not the fact that the equation of linear change is a deterministic model and the GLM is a probabilistic model with parameters fitted from data, this is something we can (and will) do for \\(a\\) as well. The profound difference between the models is the role given to the passage of time: The linear difference equation represents changes in \\(Y\\) as a function of the physical dimension time and \\(Y\\) itself. The GLM represents changes in \\(Y\\) as a function of a linear predictor composed of additive components that can be regarded as independent sources of variation that sum up to the observed values of \\(Y\\). Retreived from www.statsoft.com↩ "],
["getting-started-with-r.html", "3.2 Getting started with R", " 3.2 Getting started with R In this tutorial on estimating Effect Size Confidence Intervals (ESCI) there are a lot of examples on how to use R. It was written as an addendum for a post on the Open Science Collaboration Blog, which contains many interesting entries on diverse subjects (like behavioural priming, theoretical amnesia and anonymous peer review) "],
["plotTS.html", "3.3 The time series object", " 3.3 The time series object A time series object is expected to have a time-dimension on the x-axis. This is very convenient, because R will generate the time axis for you by looking at the time series properties attribute of the object. Even though we are not working with measurement ourcomes, consider a value at a time-index in a time series object a sample: Start - The value of time at the first sample in the series (e.g., \\(0\\), or \\(1905\\)) End - The value of time at the last sample in the series (e.g., \\(100\\), or \\(2005\\)) Frequency - The amount of time that passed between two samples, or, the sample rate (e.g., \\(0.5\\), or \\(10\\)) Examples of using the time series object. # Get a timeseries of 100 random numbers Y &lt;- ts(rnorm(100)) # plot.ts plot(Y) # Get sample rate info tsp(Y) ## [1] 1 100 1 # Extract the time vector time(Y) ## Time Series: ## Start = 1 ## End = 100 ## Frequency = 1 ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## [18] 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ## [35] 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 ## [52] 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 ## [69] 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 ## [86] 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 For now, these values are in principle all arbitrary units (a.u.). These settings only make sense if they represent the parameters of an actual measurement procedure. It is easy to adjust the time vector, by assigning new values using tsp() (values have to be possible given the timeseries length). For example, suppose the sampling frequency was \\(0.1\\) instead of \\(1\\) and the Start time was \\(10\\) and End time was \\(1000\\). # Assign new values (tsp(Y) &lt;- c(10, 1000, .1)) ## [1] 1e+01 1e+03 1e-01 # Time axis is automatically adjusted time(Y) ## Time Series: ## Start = 10 ## End = 1000 ## Frequency = 0.1 ## [1] 10 20 30 40 50 60 70 80 90 100 110 120 130 140 ## [15] 150 160 170 180 190 200 210 220 230 240 250 260 270 280 ## [29] 290 300 310 320 330 340 350 360 370 380 390 400 410 420 ## [43] 430 440 450 460 470 480 490 500 510 520 530 540 550 560 ## [57] 570 580 590 600 610 620 630 640 650 660 670 680 690 700 ## [71] 710 720 730 740 750 760 770 780 790 800 810 820 830 840 ## [85] 850 860 870 880 890 900 910 920 930 940 950 960 970 980 ## [99] 990 1000 3.3.1 Plotting a ts object as a time series Depending on which packages you use, there will be different settings applied to time series objects created by ts(). Below are some examples of differences between plotting routines. require(lattice) # Needed for plotting require(latticeExtra) # Needed for plotting # stats::plot.ts plot(Y, lwd = 2, main = &quot;stats::plot.ts&quot;) # lattice::xyplot.ts xyplot(Y, lwd = 2, main = &quot;lattice::xyplot.ts&quot;) 3.3.2 Plotting multiple time series in one figure Plot multiple timeseries in frames with plot.ts() in package::stats. This function takes a matrix as input, here we use cbind( ... ). # stats::plot.ts plot(cbind(Y, cumsum(Y), cumsum(c(0,diff(Y))) ), yax.flip = TRUE, col = &quot;blue&quot;, frame.plot = TRUE) title(main = expression(paste(&quot;Random Numbers: &quot;,N(0,sigma))), xlab = &quot;time (a.u.)&quot;) Plot multiple timeseries in one graph with ts.plot() in package::graphics. This function can handle multiple ts objects as arguments. # graphics::ts.plot ts.plot(Y, cumsum(Y), cumsum(c(0,diff(Y))), gpars = list(xlab = &quot;time (a.u.)&quot;, ylab = expression(Y(t)), main = expression(paste(&quot;Random Numbers: &quot;,N(0,sigma))), lwd = rep(2,3), lty = c(1:3), col = c(&quot;darkred&quot;,&quot;darkblue&quot;,&quot;darkgreen&quot;) ) ) legend(0, -10, c(&quot;Y&quot;,&quot;cumsum(Y)&quot;, &quot;cumprod(Y)&quot;), lwd = rep(2,3), lty = c(1:3), col = c(&quot;darkred&quot;,&quot;darkblue&quot;,&quot;darkgreen&quot;), merge = TRUE, cex=.9) Use xyplot() in package::lattice to create a plot with panels. The easiest way to do this is to create a dataset in so-called “long” format. This means the variable to plot is in 1 column and other variables indicate different levels, or conditions under which the variable was observed or simulated. Function ldply() is used to generate \\(Y\\) for three different settings of \\(r\\). The values of \\(r\\) are passed as a list and after a function is applied the result is returned as a dataframe. require(plyr) # Needed for function ldply() # Create a long format dataframe for various values for `r` data &lt;- cbind.data.frame(Y = c(as.numeric(Y), cumsum(Y), cumsum(c(0,diff(Y)))), time = c(time(Y), time(Y), time(Y)), label = factor(c(rep(&quot;Y&quot;,length(Y)), rep(&quot;cumsum(Y)&quot;,length(Y)), rep(&quot;cumsum(diff(Y))&quot;,length(Y)))) ) # Plot using the formula interface xyplot(Y ~ time | label, data = data, type = &quot;l&quot;, main = expression(paste(&quot;Random Numbers: &quot;,N(0,sigma)))) "],
["the-return-plot.html", "3.4 The return plot", " 3.4 The return plot To create a return plot the values of \\(Y\\) have to be shifted by a certain lag. The functions lead() and lag() in package::dplyr are excellent for this purpose (note that dplyr::lag() behaves different from stats::lag()). # Function lag() and lead() require(dplyr) # Get exponential growth Y &lt;- rnorm(1000) Y1 &lt;- Y/max(Y) # Get logistic growth in the chaotic regime Y2 &lt;- cumsum(c(0,diff(Y)))/max(cumsum(c(0,diff(Y)))) # Use the `lag` function from package `dplyr` op &lt;- par(mfrow = c(1,2), pty = &quot;s&quot;) plot(dplyr::lag(Y1), Y1, xy.labels = FALSE, pch = 16, xlim = c(0,1), ylim = c(0,1), xlab = &quot;Y(t)&quot;, ylab = &quot;Y(t+1)&quot;, main = &quot;rnorm(1000) / max&quot;) plot(dplyr::lag(Y2), Y2, xy.labels = FALSE, pch = 16, xlim = c(0,1), ylim = c(0,1), xlab = &quot;Y(t)&quot;, ylab = &quot;Y(t+1)&quot;, main = &quot;cumsum(diff(Y)) / max&quot;) par(op) Use l_ply() from package::plyr to create return plots with different lags. The l_ before ply means the function will take a list as input to a function, but it will not expect any data to be returned, for example in the case of a function that is used to plot something. # Explore different lags op &lt;- par(mfrow = c(1,2), pty = &quot;s&quot;) plyr::l_ply(1:4, function(l) plot(lag(Y2, n = l), Y2, xy.labels = FALSE, pch = 16, xlim = c(0,1), ylim = c(0,1), xlab = &quot;Y(t)&quot;, ylab = paste0(&quot;Y(t+&quot;,l,&quot;)&quot;), cex = .8)) par(op) "],
["spreadsheet-versus-matlab-r-etc-.html", "3.5 Spreadsheet versus Matlab, R, etc.", " 3.5 Spreadsheet versus Matlab, R, etc. Coding change processes (difference equations) in Matlab and R is always easier than using a spreadsheet. One obvious way to do it is to use a counter variable representing the iterations of time in a for ... next loop. The iterations should run over a vector (which is the same concept as a row or a column in a spreadsheet: An indexed array of numbers or characters). The first entry should be the starting value, so the vector index \\(1\\) represents \\(Y_0\\). The loop can be implemented a number of ways, for example as a function which can be called from a script or the command / console window. In R working with functions is easy, and very much recommended, because it will speed up calculations considerably, and it will reduce the amount of code you need to write. You need to gain some experience with coding in R before you’ll get it right. In order to get it lean and clean (and possibly even mean as well) you’ll need a lot of experience with coding in R,therefore, we will (eventually) provide you the functions you’ll need to complete the assignments. All you have to do is figure out how to use, or modify them to suit your specific needs. "],
["basic-tsa.html", "Chapter 4 Basic TSA", " Chapter 4 Basic TSA "],
["applications.html", "Chapter 5 Applications", " Chapter 5 Applications Some significant applications are demonstrated in this chapter. "],
["example-one.html", "5.1 Example one", " 5.1 Example one "],
["example-two.html", "5.2 Example two", " 5.2 Example two "],
["final-words.html", "Chapter 6 Final Words", " Chapter 6 Final Words We have finished a nice book. "],
["final-words-1.html", "Chapter 7 Final Words", " Chapter 7 Final Words We have finished a nice book. "],
["final-words-2.html", "Chapter 8 Final Words", " Chapter 8 Final Words We have finished a nice book. "],
["final-words-3.html", "Chapter 9 Final Words", " Chapter 9 Final Words We have finished a nice book. "],
["list-of-terms.html", "A List of terms", " A List of terms Adaptive Behaviour System behaviour that appears to be (partially) coordinated by previously ‘experienced events’ Analytic solution The solution to a difference or differential equation allows one to find any state of the system without the need to iterate the model starting from some initial condition. There are very few (systems of) equations for which analytical solutions exist Attractor The status that a dynamic system eventually “settles down to”. An attractor is a set of values in the phase space to which a system migrates over time, or iterations. Attractors can have as many dimensions as the number of variables that influence its system Basin of attraction A region in phase space associated with a given attractor. The basin of attraction of an attractor is the set of all (initial) points that eventually end up in that attractor Behaviour (of a dynamic system) The temporal evolution of states of a system according to one or more rules (also known as state propagation rules, or, iterative processes). Models of the behaviour of dynamic systems use difference or differential equations to describe the iterative processes hypothesized to underly the temporal evolution Bifurcation A clearly observable qualitative change in the behavioural mode (attractor state) of a dynamic system associated with continuous change in one or more control parameters (also known as Phase-, State-, or Order- Transition). The value of a control parameter at which a bifurcation occurs is often non-specific, or trivial Bifurcation diagram Visual summary of the succession of period-doubling bifurcations produced by gradual changes in the control parameter(s) Catasrophe theory Mathematical resreach program describing how gradual change in some parameters can lead to disprortionally large changes in another parameter, called catastrophes (similair to bifurcations, Phase-, State-, or Order-transitions). ‘This kind of behavior has been summarized succinctly in the phrase “the straw that broke the camel’s back”.’ (Gilmore, 1992). Catastrophe flags Markers indicative for a physical system that is describe by a catastrophe. There are 5 ‘classical’ flags and 3 ‘diagnostic’ flags. Classical: bimodality, sudden jumps, inaccessibility, sensitivity &amp; hyesteresis. Diagnostic: divergence from linear response, critical slowing down and critical fluctuations. Diagnostic flags can be used as early-warning signals. Complex Network A network with of many nodes and likely many substructures depending on thet nature and distribution of connections between nodes Complex system Spatially and/or temporally extended nonlinear systems characterized by emergent properties and self-organised behavioural modes at a global, or, macro-level (the system as a whole), that is often different from the characteristic behaviour at a local, or, micro-level (behaviour of the individual parts that constitute the whole) Complexity science Complexity science studies how systems that consist of many components can generate relatively simple and stable (nonrandom) behaviour. Important behavioural phenomena studied in Complexity Science are synchronisation, adaptation and coordination of behaviour across many different temporal and spatial scales, emergent properties and collective behaviour, holism and self-organisation Component dominant dynamics A causal ontology in which observed behaviour is explained by assuming it is the result of a chain of independent efficient causes (components) Control parameter A variable that controls the global behaviour of a dynamic system. For certain values of the parameter, transitions between qualitatively different behavioural modes (orders) can occur. Critical fluctuations An early warning signal for a phase transition that is characterised by an increase in fluctuations (variability) of the behaviour of the system. The increase occurs because the self-organised transition from one state to another relaxes the contraints on the degrees of freedom a system has available to generate its behaviour, allowing states and behavioural modes to appear that were previously inaccesible. Critical slowing down An early warning signal for a phase transition that is characterised by an increase in the duration of relaxation times. If it takes longer for the system to return to the state it was perturbed from, this implies the emergence of a new stable state is imminent Deterministic Chaos Behaviour of a dynamic system that “looks random, but is not” (Lorenz, 1973). The dynamics can be characterised as follows: 1) A-periodic, no point or trajectory in state space will exactly recur; 2) Sensitive dependence in initial conditions; 3) Bounded, not all theoretically possible degrees of freedom are available to the system; 4) The origin of this behaviour is deterministic, not stochastic Difference equation A function specifying the underlying change process in a variable from one discrete point in time to another Differential equation A function specifying the underlying change process of a variable in continuous time Dimension See embedding dimension, box-counting dimension, correlation dimension, information dimension, dimension of a system Dimensions of a system The set of variables that define a system. Iterative processes operate on the dimensions of a system Dynamic system A set of equations specifying how certain variables change over time. The equations specify how to determine (compute) the new values as a function of their current values and control parameters. The functions, when explicit, are either difference equations or differential equations. Dynamic systems may be stochastic or deterministic. In a stochastic system, new values come from a probability distribution. In a deterministic system, a single new value is associated with any current value Early warning signals Critical slowing down and critical fluctuations. Early-warning signals indicate instability in the existing state which may result in a qualitative shift towards a new state (phase transition / catastrophe). Early-warning signals are similair to diagnostic catastrophe flags. Effective Complexity “The effective complexity of an entity is the length of a highly compressed description of its regularities.” (Gell-man &amp; Lloyd, 2004) Embedding Dimension Successive N-tuples of points in a time series are treated as points in N dimensional space. The points are said to reside in embedding dimensions of size N, for N = 1, 2, 3, 4, … etc. Emergence A complex system can generate emergent behaviour or display emergent properties that are novel and unexpected, that is, they are not predictable from the behaviour and proprties of the components of the system Entropy Relative absence of order/redundancy in a system. The degrees of freedom a system has available for generating its behavior: Possibility Epigenetic landscape (potential lanscape) A hypothetical landscape describing the relative stability of behavioural modes of a system over time Experienced event An interaction of a system with its environment that changed the internal structure/organization of the system such that it can be said to display adaptive behaviour. “Interaction with after-effects”. Random behavior is “Interaction without after-effects”. flow ~ A differential equation Fractal An irregular shape with self-similarity. It has infinite detail, and cannot be differentiated. “Wherever chaos, turbulence, and disorder are found, fractal geometry is at play” (Briggs and Peat, 1989). Fractal Dimension A measure of a geometric object that can take on fractional values. At first used as a synonym to Hausdorff dimension, fractal dimension is currently used as a more general term for a measure of how fast length, area, or volume increases with decrease in scale. (Peitgen, Jurgens, &amp; Saupe, 1992a). Graph theory Models in which associations between mathematical objects are defined as edges (connections) between vertices (nodes) Hausdorff Dimension A measure of a geometric object that can take on fractional values. (see fractal dimension). Holism (epistemic) “some property of a whole would be holistic if, according to the theory in question, there is no way we can find out about it using only local means, i.e., by using only all possible non-holistic resources available to an agent.” (Seevinck, 2002) Idiographic approach Scientific explanation in which the goal is to generate knowledge about specific facts, events or entities. The goal is not to generalize to universal laws and first principles. Information (quantity) A measurable quantity that resolves uncertainty about the state of a system by assigning a value to the uncertainty. Initial condition The starting point of a dynamic system, the initial state of a system from which it evolved to the current state. Interaction dominant dynamics A causal ontology in which observed behaviour is explained by assuming it is the result of interactions between processes across many temporal and spatial scales Iteration The repeated application of a function, using its output from one application as its input for the next. Iterative function A function used to calculate the new state of a dynamic system. Iterative system A system in which one or more functions are iterated to define the system. Largest Lyapunov exponent The value of the largest exponent in a spectrum of exponents (the Lyapunov spectrum), coefficients of time, that reflect the rate of departure (divergence) of dynamic orbits of a system. The largest exponent indicates the extent to which the behaviour of a system is sensitive to initial conditions. Limit cycle An attractor that is periodic in time, that is, that cycles periodically through an ordered sequence of states. Limit points Points in phase space. There are three kinds: attractors, repellors, and saddle points. A system moves away from repellors and towards attractors. A saddle point is both an attractor and a repellor, it attracts a system in certain regions, and repels the system to other regions. Linear function of predictors A linear equation is of predictors is of the form y=a*x(i)+b, in which variable y varies ‘linearly’ with other variables x(i). In this equation, ‘a’ determines the slope of the line and ‘b’ reflects the y-intercept, the value y obtains when all x(i) equal zero. Linear function of time A linear function of time is of the form ŷ(t) = a*y(t) + b, in which variable y varies ‘linearly’ with time ‘t’, that is, with itself at an earlier moment in time. In this equation ‘a’ determines the rate with which ‘y’ will change as time passes, ‘b’ reflects the initial condition, the value y obtains when t equals zero. map … A difference equation Nonlinear dynamics The study of dynamic systems whose functions specify that change is not a linear function of time. Orbit (trajectory) A sequence of coordinates (a path) through the phase space of a system. Order “order is essentially the arrival of redundancy in a system, a reduction of possibilities”(Von Förster, 2003). Any form of nonrandom association or dependency that exists between parts of a system, its behaviour over time and/or its environment is a form of order. In scientific explanation of behaviour, the presence of order in non-artificial systems must be explained and should not be (implicitly) assumed. Order Parameter A nominal variable that indexes qualitatively different behavioural modes of a system, for example the phases of matter (gas, liquid, solid, plasma) Period-doubling The change in dynamics in which a N-point attractor is replaced by a 2N-point attractor. Phase portrait The collection of all trajectories from all possible starting points in the phase space of a dynamic system. Phase space An abstract space used to represent the behavior of a system. Its dimensions are the variables of the system. Thus a point in the phase space defines a potential state of the system. The points actually achieved by a system depend on its iterative function and initial condition (starting point). Phase transition A transition between qualitatively different behavioural modes Potential function A function that describes the order paremeter of a system, that is, it describes the relative stability of the potential end-states (attractor states) a system can settle into. The paramaters of the potential function include the control parameter. Power-law scaling A relationship between two variables that is linear on doubly logarithmic coordinates, meaning the law is experessed in increments that represent ‘power’ Recursive process For our purposes, “recursive” and “iterative” are synonyms. Thus recursive processes are iterative processes, and recursive functions are iterative functions. Relaxation time The time it takes for a system to return to a stable state after it was perturbed enough to leave that state. A characteristic warning signal of an imminent phase transition is an increase relaxation times, also known as critical slowing down. Repellors One type of limit point. A point in phase space that a system moves away from. Return map Plot of time series values vs.a delayed copy of itself. A return plot can be used to get an idea about the functional form of the iterative process, it is a simple variant of delay embedding. Saddle point A point, usually in three dimensional state space, that both attracts and repels, attracting in one dimension and repelling to another. Scale free network A network in which the distribution of the number of connections of a node and their frequency of occurence follows a power-law in which there are just a few nodes with many connections and many nodes with just a few connections Self-affinity An infinite nesting of characteristic structure on all scales. Strict self-affinity refers to a form of which all substructures are affine transformation, which means the different dimensions of the system can be scaled by their own exponent. Statistical self-affinity refers to an approximate equivalence of form at all scales. Self-similarity An infinite nesting of characteristic structure on all scales. Strict self-similarity refers to a form of which all substructures can be considered scaling tranformations, larger or smaller copies scaled by a single exponent for all dimensions of the structure. Statistical self-similarity refers to an approximate equivalence of scaled structure. Sensitive dependence on initial conditions A property of chaotic systems. A dynamic system has sensitivity to initial conditions when very small differences in starting values result in very different behavior. If the orbits of nearby starting points diverge, the system has sensitivity to initial conditions. Small world network Many real-world networks have a small average shortest path length, but also a clustering coefficient that is significantly higher than expected by chance. These networks are extremely efficient, each node in a very large network can still be reach in just a few steps (the ’six degrees of seperation` phenomenon). State A coordinate in state space designating the current status of a dynamic system. The elements of the coordinates are values on the dimensions of the system that span the state space. State space A hypothetical space spanned by the dimensions of the system. Each combination of values of variables that represent the dimension is a state of the system, it is a coordinate in state space. State space (phase space) An abstract space used to represent the behaviour of a system. Its dimensions are the variables of the system. Thus a point in the phase space defines a potential state of the system. Strange attractor An attractor state representing chaotic dynamics: a-periodic, bounded, and sensitive dependence on initial conditions System An entity that can be described as a composition of components according to some organising principle. Organising principles describe how parts of the system relate to the whole and. Time series A record of observations (data points) of behaviour over time. Trajectory (orbit) A sequence of positions (path) of a system in its phase space. The path from its starting point (initial condition) to and within its attractor. Transient time (transient behaviour) The time it takes for a system to transition from one stable state (behavioural mode, attractor state) into another, during which the system displays transient behaviour "],
["references.html", "References", " References "]
]
